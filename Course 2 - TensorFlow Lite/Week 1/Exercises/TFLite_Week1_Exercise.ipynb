{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TFLite_Week1_Exercise.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"id":"zX4Kg8DUTKWO"},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Za8-Nr5k11fh"},"source":["##### Copyright 2018 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","id":"Eq10uEbw0E4l"},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"06ndLauQxiQm"},"source":["# Train Your Own Model and Convert It to TFLite"]},{"cell_type":"code","metadata":{"id":"BX_v6aX3UW1o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dtav_aq2xh6n"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%201/Exercises/TFLite_Week1_Exercise.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n","    Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%201/Exercises/TFLite_Week1_Exercise.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n","    View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"Ka96-ajYzxVU"},"source":["This notebook uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n","\n","<table>\n","  <tr><td>\n","    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n","         alt=\"Fashion MNIST sprite\"  width=\"600\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n","  </td></tr>\n","</table>\n","\n","Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing we'll use here.\n","\n","This uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n","\n","We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and load the Fashion MNIST data directly from TensorFlow:"]},{"cell_type":"markdown","metadata":{"id":"rjOAfhgd__Sp"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"Bp_nvHnh_tDo","executionInfo":{"status":"ok","timestamp":1601373834254,"user_tz":-480,"elapsed":1907,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["try:\n","    %tensorflow_version 2.x\n","except:\n","    pass"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"pfyZKowNAQ4j","executionInfo":{"status":"ok","timestamp":1601427470848,"user_tz":-480,"elapsed":1601,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"bd112b32-aa48-4e0e-af08-cbe5bf38fdc1","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["import pathlib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","\n","print('\\u2022 Using TensorFlow Version:', tf.__version__)\n","print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"],"execution_count":104,"outputs":[{"output_type":"stream","text":["• Using TensorFlow Version: 2.3.0\n","• GPU Device Found.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hu0NUNryTU2O","executionInfo":{"status":"ok","timestamp":1601423317638,"user_tz":-480,"elapsed":2811,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"3fed8b74-0d18-4576-f169-5e9a39ad31ce","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(tf.config.list_physical_devices('GPU')) > 0 "],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"tadPBTEiAprt"},"source":["# Download Fashion MNIST Dataset\n","\n","We will use TensorFlow Datasets to load the Fashion MNIST dataset. "]},{"cell_type":"code","metadata":{"id":"XcNwi6nFKneZ","executionInfo":{"status":"ok","timestamp":1601427481534,"user_tz":-480,"elapsed":1617,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))\n","splits = (\"train[:80%]\", \"train[:10%]\", \"train[:10%]\")  # my try 1\n","# splits = (\"train[:80]\", \"train[:10]\", \"train[:10]\")\n","\n","# SPLIT_WEIGHTS = (8, 1, 1)\n","# splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\n","\n","\n","splits, info = tfds.load('fashion_mnist', with_info=True, as_supervised=True, split=splits)\n","\n","(train_examples, validation_examples, test_examples) = splits\n","\n","num_examples = info.splits['train'].num_examples\n","num_classes = info.features['label'].num_classes"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"zOwgY8U5SNwg","executionInfo":{"status":"ok","timestamp":1601427484785,"user_tz":-480,"elapsed":1615,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"233075b6-3967-45a3-997b-afb9e57d5750","colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["splits"],"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n"," <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n"," <DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>)"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"id":"z3EhsIwNTx1Y","executionInfo":{"status":"ok","timestamp":1601427338745,"user_tz":-480,"elapsed":1634,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"f5af0129-08e9-422c-bae5-5175d43d3b33","colab":{"base_uri":"https://localhost:8080/","height":631}},"source":["# 查看 fashion mnist 信息\n","info"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tfds.core.DatasetInfo(\n","    name='fashion_mnist',\n","    version=3.0.0,\n","    description='Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.',\n","    homepage='https://github.com/zalandoresearch/fashion-mnist',\n","    features=FeaturesDict({\n","        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n","        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n","    }),\n","    total_num_examples=70000,\n","    splits={\n","        'test': 10000,\n","        'train': 60000,\n","    },\n","    supervised_keys=('image', 'label'),\n","    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n","      author    = {Han Xiao and\n","                   Kashif Rasul and\n","                   Roland Vollgraf},\n","      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n","                   Algorithms},\n","      journal   = {CoRR},\n","      volume    = {abs/1708.07747},\n","      year      = {2017},\n","      url       = {http://arxiv.org/abs/1708.07747},\n","      archivePrefix = {arXiv},\n","      eprint    = {1708.07747},\n","      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n","      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n","      bibsource = {dblp computer science bibliography, https://dblp.org}\n","    }\"\"\",\n","    redistribution_info=,\n",")"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"HaaA-BLbUF6t","executionInfo":{"status":"ok","timestamp":1601427353313,"user_tz":-480,"elapsed":1639,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"b846ff2c-3bbd-40c5-d8bc-0d379dfd5826","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["print(num_examples)\n","print(num_classes)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["60000\n","10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4suH6ZjcYLb4","executionInfo":{"status":"ok","timestamp":1601427355929,"user_tz":-480,"elapsed":1610,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"],"execution_count":98,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"no9pue8bl61r"},"source":["The class names are not included with the dataset, so we will specify them here."]},{"cell_type":"code","metadata":{"id":"-eAv71FRm4JE","executionInfo":{"status":"ok","timestamp":1601427357873,"user_tz":-480,"elapsed":1758,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ypXXZbVmYQF4"},"source":["0 T恤/上衣\n","1\t裤子\n","2\t套头衫\n","3\t连衣裙\n","4\t外套\n","5\t凉鞋\n","6\t衬衫\n","7\t运动鞋\n","8\t包\n","9\t短靴"]},{"cell_type":"code","metadata":{"id":"hXe6jNokqX3_","executionInfo":{"status":"ok","timestamp":1601424409748,"user_tz":-480,"elapsed":1229,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# Create a labels.txt file with the class names\n","with open('labels.txt', 'w') as f:\n","    f.write('\\n'.join(class_names))"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"iubWCThbdN8K","executionInfo":{"status":"ok","timestamp":1601424411936,"user_tz":-480,"elapsed":720,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# The images in the dataset are 28 by 28 pixels.\n","IMG_SIZE = 28"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAeMeXZjYb9d","executionInfo":{"status":"ok","timestamp":1601425963188,"user_tz":-480,"elapsed":1638,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"5974fbe0-b184-45c1-81f9-0f705affd45b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_examples"],"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"qXuOAIwsbTnw","executionInfo":{"status":"ok","timestamp":1601426675766,"user_tz":-480,"elapsed":1723,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"cd994bda-30dd-4b30-a104-d5251de89464","colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["# 查看dataset样本数据\n","for img, label in train_examples.take(1):\n","  print(img.shape) # img\n","  # print(label.numpy()) \n","  # print(img.numpy())\n","  img_example = np.squeeze(img.numpy())\n","  img_lable = label.numpy()\n","  plt.figure()\n","  plt.imshow(np.squeeze(img.numpy()))\n","  plt.colorbar()\n","  plt.grid(False)\n","  plt.show()\n","img.shape"],"execution_count":82,"outputs":[{"output_type":"stream","text":["(28, 28, 1)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["TensorShape([28, 28, 1])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"dkWUwYCQd-kX","executionInfo":{"status":"ok","timestamp":1601426686998,"user_tz":-480,"elapsed":1621,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"67d6512b-7156-487e-c173-ca6a6c1a57dd","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["img_example"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,  18,  77, 227, 227,\n","        208, 210, 225, 216,  85,  32,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  61, 100,  97,  80,  57, 117,\n","        227, 238, 115,  49,  78, 106, 108,  71,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  81, 105,  80,  69,  72,  64,  44,\n","         21,  13,  44,  69,  75,  75,  80, 114,  80,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,  26,  92,  69,  68,  75,  75,  71,  74,\n","         83,  75,  77,  78,  74,  74,  83,  77, 108,  34,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,  55,  92,  69,  74,  74,  71,  71,  77,\n","         69,  66,  75,  74,  77,  80,  80,  78,  94,  63,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,  63,  95,  66,  68,  72,  72,  69,  72,\n","         74,  74,  74,  75,  75,  77,  80,  77, 106,  61,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,  80, 108,  71,  69,  72,  71,  69,  72,\n","         75,  75,  72,  72,  75,  78,  72,  85, 128,  64,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,  88, 120,  75,  74,  77,  75,  72,  77,\n","         74,  74,  77,  78,  83,  83,  66, 111, 123,  78,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,  85, 134,  74,  85,  69,  75,  75,  74,\n","         75,  74,  75,  75,  81,  75,  61, 151, 115,  91,  12,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  10,  85, 153,  83,  80,  68,  77,  75,  74,\n","         75,  74,  75,  77,  80,  68,  61, 162, 122,  78,   6,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  30,  75, 154,  85,  80,  71,  80,  72,  77,\n","         75,  75,  77,  78,  77,  75,  49, 191, 132,  72,  15,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  58,  66, 174, 115,  66,  77,  80,  72,  78,\n","         75,  77,  78,  78,  77,  66,  49, 222, 131,  77,  37,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  69,  55, 179, 139,  55,  92,  74,  74,  78,\n","         74,  78,  77,  75,  80,  64,  55, 242, 111,  95,  44,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  74,  57, 159, 180,  55,  92,  64,  72,  74,\n","         74,  77,  75,  77,  78,  55,  66, 255,  97, 108,  49,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  74,  66, 145, 153,  72,  83,  58,  78,  77,\n","         75,  75,  75,  72,  80,  30, 132, 255,  37, 122,  60,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  80,  69, 142, 180, 142,  57,  64,  78,  74,\n","         75,  75,  75,  72,  85,  21, 185, 227,  37, 143,  63,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  83,  71, 136, 194, 126,  46,  69,  75,  72,\n","         75,  75,  75,  74,  78,  38, 139, 185,  60, 151,  58,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   4,  81,  74, 145, 177,  78,  49,  74,  77,  75,\n","         75,  75,  75,  74,  72,  63,  80, 156, 117, 153,  55,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,  10,  80,  72, 157, 163,  61,  55,  75,  77,  75,\n","         77,  75,  75,  75,  77,  71,  60,  98, 156, 132,  58,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,  13,  77,  74, 157, 143,  43,  61,  72,  75,  77,\n","         75,  74,  77,  77,  75,  71,  58,  80, 157, 120,  66,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,  18,  81,  74, 156, 114,  35,  72,  71,  75,  78,\n","         72,  66,  80,  78,  77,  75,  64,  63, 165, 119,  68,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,  23,  85,  81, 177,  57,  52,  77,  71,  78,  80,\n","         72,  75,  74,  77,  77,  75,  64,  37, 173,  95,  72,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,  26,  81,  86, 160,  20,  75,  77,  77,  80,  78,\n","         80,  89,  78,  81,  83,  80,  74,  20, 177,  77,  74,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,  49,  77,  91, 200,   0,  83,  95,  86,  88,  88,\n","         89,  88,  89,  88,  83,  89,  86,   0, 191,  78,  80,  24,   0,\n","          0,   0],\n","       [  0,   0,   0,  54,  71, 108, 165,   0,  24,  57,  52,  57,  60,\n","         60,  60,  63,  63,  77,  89,  52,   0, 211,  97,  77,  61,   0,\n","          0,   0],\n","       [  0,   0,   0,  68,  91, 117, 137,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,  18, 216,  94,  97,  57,   0,\n","          0,   0],\n","       [  0,   0,   0,  54, 115, 105, 185,   0,   0,   1,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 153,  78, 106,  37,   0,\n","          0,   0],\n","       [  0,   0,   0,  18,  61,  41, 103,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 106,  47,  69,  23,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"pBxONcOreBPG","executionInfo":{"status":"ok","timestamp":1601426697770,"user_tz":-480,"elapsed":1606,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"e7573a20-3839-4d21-a5d7-fe64a71899fc","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["img_lable"],"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"ZAkuq0V0Aw2X"},"source":["# Preprocessing data"]},{"cell_type":"markdown","metadata":{"id":"_5SIivkunKCC"},"source":["## Preprocess"]},{"cell_type":"code","metadata":{"id":"BwyhsyGydHDl","executionInfo":{"status":"ok","timestamp":1601427501928,"user_tz":-480,"elapsed":1612,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# EXERCISE: Write a function to normalize the images.\n","\n","def format_example(image, label):\n","    # Cast image to float32\n","    image = tf.cast(image, tf.float32)\n","    # image = tf.image.resize(image, (IMG_SIZE,IMG_SIZE)) \n","        \n","    # Normalize the image in the range [0, 1]\n","    image = image / 255.0\n","    \n","    # label = tf.keras.utils.to_categorical(label,num_classes)\n","    return image, label"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAlBlXOUMwqe","executionInfo":{"status":"ok","timestamp":1601427535979,"user_tz":-480,"elapsed":1632,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# Specify the batch size\n","BATCH_SIZE = 256"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"id":"374XiOyteGrd","executionInfo":{"status":"error","timestamp":1601426843166,"user_tz":-480,"elapsed":1419,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"9ee2bdee-0c22-447c-a5fa-47e913aa3171","colab":{"base_uri":"https://localhost:8080/","height":174}},"source":["# img_example_cvt, img_label_cvt = format(img_example, img_lable)"],"execution_count":88,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-88-12bb100f424e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_example_cvt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_label_cvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_lable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: format() argument 2 must be str, not numpy.int64"]}]},{"cell_type":"markdown","metadata":{"id":"JM4HfIJtnNEk"},"source":["## Create Datasets From Images and Labels"]},{"cell_type":"code","metadata":{"id":"GlHtBbKEg5bX","executionInfo":{"status":"ok","timestamp":1601427511640,"user_tz":-480,"elapsed":1609,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["\n","# Create Datasets\n","train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)\n","validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)\n","test_batches = test_examples.batch(1).map(format_example)"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxe2I3oxLDhq","executionInfo":{"status":"error","timestamp":1601427377230,"user_tz":-480,"elapsed":1617,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"02bf20c5-7876-488e-df06-20dfa7beb472","colab":{"base_uri":"https://localhost:8080/","height":522}},"source":["# Create Datasets\n","# train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)\n","# validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)\n","# test_batches = test_examples.batch(1).map(format_example)\n","# # train_batches = train_examples.shuffle(num_examples//4).map(format_example).batch(BATCH_SIZE).prefetch(1)\n","# validation_batches = validation_examples.map(format_example).batch(BATCH_SIZE).prefetch(1)\n","# test_batches = test_examples.map(format_example).batch(1)"],"execution_count":102,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-8250d688cf49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train_batches = train_examples.shuffle(num_examples//4).map(format_example).batch(BATCH_SIZE).prefetch(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   2507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m       return DatasetV1Adapter(\n\u001b[0;32m-> 2509\u001b[0;31m           MapDataset(self, map_func, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   2510\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m       return DatasetV1Adapter(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4046\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4047\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3363\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3364\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-100-ade9f1c5f4a3>:11 format_example  *\n        label = tf.keras.utils.to_categorical(label,num_classes)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/np_utils.py:69 to_categorical  **\n        y = np.array(y, dtype='int')\n\n    TypeError: __array__() takes 1 positional argument but 2 were given\n"]}]},{"cell_type":"markdown","metadata":{"id":"EextdWTYXkA2"},"source":["dataset.cache() 功能！！ ToDo"]},{"cell_type":"code","metadata":{"id":"ZZ7hSAVLU4Z_","executionInfo":{"status":"ok","timestamp":1601427554802,"user_tz":-480,"elapsed":3293,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"e3ad1e72-6879-408b-9105-0bea1675a249","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["for image_batch, label_batch in train_batches.take(1):\n","    pass\n","\n","image_batch.shape"],"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([256, 28, 28, 1])"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"code","metadata":{"id":"FiZHWjioVPVG","executionInfo":{"status":"ok","timestamp":1601427556452,"user_tz":-480,"elapsed":970,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"44972c29-be94-4197-e5b1-7d682f11a877","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["label_batch.shape"],"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([256])"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"code","metadata":{"id":"bO3HoQB-VusW","executionInfo":{"status":"ok","timestamp":1601427560824,"user_tz":-480,"elapsed":1570,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"2d49b989-22bf-4d7a-aa81-4dc07aa320be","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["for test_image_batch, test_label_batch in validation_batches.take(1):\n","  pass\n","test_image_batch.shape"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([256, 28, 28, 1])"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"7EhhQNyuV-0V","executionInfo":{"status":"ok","timestamp":1601427562939,"user_tz":-480,"elapsed":1397,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"67fde07d-d276-40cb-ce83-422eba798b72","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_label_batch.shape"],"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([256])"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"M-topQaOm_LM"},"source":["# Building the Model"]},{"cell_type":"markdown","metadata":{"id":"kVjBzM7Xl615"},"source":["```\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 16)        160       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3872)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                247872    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 253,322\n","Trainable params: 253,322\n","Non-trainable params: 0\n","```"]},{"cell_type":"code","metadata":{"id":"kDqcwksFB1bh","executionInfo":{"status":"ok","timestamp":1601424127202,"user_tz":-480,"elapsed":1631,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# EXERCISE: Build and compile the model shown in the previous cell.\n","\n","model = tf.keras.Sequential([\n","    # Set the input shape to (28, 28, 1), kernel size=3, filters=16 and use ReLU activation,\n","    tf.keras.layers.Conv2D(kernel_size=3, filters=16, activation='relu',input_shape=(28, 28, 1)),\n","      \n","    tf.keras.layers.MaxPooling2D(),\n","      \n","    # Set the number of filters to 32, kernel size to 3 and use ReLU activation \n","    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n","      \n","    # Flatten the output layer to 1 dimension\n","    tf.keras.layers.Flatten(),\n","      \n","    # Add a fully connected layer with 64 hidden units and ReLU activation\n","    tf.keras.layers.Dense(64, activation='relu'),\n","      \n","    # Attach a final softmax classification head\n","    tf.keras.layers.Dense(num_classes, activation='softmax')])\n","\n","# Set the appropriate loss function and use accuracy as your metric\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"_3DMDeGkbAOc","executionInfo":{"status":"ok","timestamp":1601424129375,"user_tz":-480,"elapsed":1497,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"6e075010-51a7-408d-ae9d-845152bda522","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["model.summary() "],"execution_count":45,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 3872)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                247872    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 253,322\n","Trainable params: 253,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zEMOz-LDnxgD"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"x8d4aW63bJx7","executionInfo":{"status":"ok","timestamp":1601424140104,"user_tz":-480,"elapsed":1610,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"e1cdc1ba-ab55-49f2-de9b-3ad5842786c0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["validation_batches"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"1y-388Znba0-","executionInfo":{"status":"ok","timestamp":1601424142918,"user_tz":-480,"elapsed":1624,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"90781a6b-d1cf-4a07-d165-9fccc2cb568f","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["validation_examples"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<DatasetV1Adapter shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"JGlNoRtzCP4_","executionInfo":{"status":"error","timestamp":1601427590637,"user_tz":-480,"elapsed":1650,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"f5c2e9c5-0bf4-406c-e49c-8210934d2261","colab":{"base_uri":"https://localhost:8080/","height":972}},"source":["model.fit(train_batches, \n","          epochs=10,\n","          validation_data=validation_batches)"],"execution_count":114,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-114-0a603baf7d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_batches, \n\u001b[1;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           validation_data=validation_batches)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"]}]},{"cell_type":"markdown","metadata":{"id":"TZT9-7w9n4YO"},"source":["# Exporting to TFLite\n","\n","You will now save the model to TFLite. We should note, that you will probably see some warning messages when running the code below. These warnings have to do with software updates and should not cause any errors or prevent your code from running. "]},{"cell_type":"code","metadata":{"id":"9dq78KBkCV2_"},"source":["# EXERCISE: Use the tf.saved_model API to save your model in the SavedModel format. \n","export_dir = 'saved_model/1'\n","\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"EDGiYrBdE6fl"},"source":["#@title Select mode of optimization\n","mode = \"Speed\" #@param [\"Default\", \"Storage\", \"Speed\"]\n","\n","if mode == 'Storage':\n","    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n","elif mode == 'Speed':\n","    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n","else:\n","    optimization = tf.lite.Optimize.DEFAULT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbcS9C00CzGe"},"source":["# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n","\n","converter = # YOUR CODE HERE\n","\n","# Set the optimzations\n","converter.optimizations = # YOUR CODE HERE\n","\n","# Invoke the converter to finally generate the TFLite model\n","tflite_model = # YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5PWCDsTC3El"},"source":["tflite_model_file = pathlib.Path('./model.tflite')\n","tflite_model_file.write_bytes(tflite_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SR6wFcQ1Fglm"},"source":["# Test the Model with TFLite Interpreter "]},{"cell_type":"code","metadata":{"id":"rKcToCBEC-Bu"},"source":["# Load TFLite model and allocate tensors.\n","interpreter = tf.lite.Interpreter(model_content=tflite_model)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8EpFpIBFkq8"},"source":["# Gather results for the randomly sampled test images\n","predictions = []\n","test_labels = []\n","test_images = []\n","\n","for img, label in test_batches.take(50):\n","    interpreter.set_tensor(input_index, img)\n","    interpreter.invoke()\n","    predictions.append(interpreter.get_tensor(output_index))\n","    test_labels.append(label[0])\n","    test_images.append(np.array(img))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"kSjTmi05Tyod"},"source":["#@title Utility functions for plotting\n","# Utilities for plotting\n","\n","def plot_image(i, predictions_array, true_label, img):\n","    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    \n","    img = np.squeeze(img)\n","    \n","    plt.imshow(img, cmap=plt.cm.binary)\n","    \n","    predicted_label = np.argmax(predictions_array)\n","    \n","    if predicted_label == true_label.numpy():\n","        color = 'green'\n","    else:\n","        color = 'red'\n","    \n","    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                         100*np.max(predictions_array),\n","                                         class_names[true_label]), color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","    predictions_array, true_label = predictions_array[i], true_label[i]\n","    plt.grid(False)\n","    plt.xticks(list(range(10)), class_names, rotation='vertical')\n","    plt.yticks([])\n","    thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n","    plt.ylim([0, 1])\n","    predicted_label = np.argmax(predictions_array[0])\n","\n","    thisplot[predicted_label].set_color('red')\n","    thisplot[true_label].set_color('green')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"ZZwg0wFaVXhZ"},"source":["#@title Visualize the outputs { run: \"auto\" }\n","index = 12 #@param {type:\"slider\", min:1, max:50, step:1}\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(index, predictions, test_labels, test_images)\n","plt.show()\n","plot_value_array(index, predictions, test_labels)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"076bo3FMpRDb"},"source":["# Download the TFLite Model and Assets\n","\n","If you are running this notebook in a Colab, you can run the cell below to download the tflite model and labels to your local disk.\n","\n","**Note**: If the files do not download when you run the cell, try running the cell a second time. Your browser might prompt you to allow multiple files to be downloaded. "]},{"cell_type":"code","metadata":{"id":"XsPXqPlgZPjE"},"source":["try:\n","    from google.colab import files\n","    \n","    files.download(tflite_model_file)\n","    files.download('labels.txt')\n","except:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H8t7_jRiz9Vw"},"source":["# Prepare the Test Images for Download (Optional)"]},{"cell_type":"code","metadata":{"id":"Fi09nIps0gBu"},"source":["!mkdir -p test_images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sF7EZ63J0hZs"},"source":["from PIL import Image\n","\n","for index, (image, label) in enumerate(test_batches.take(50)):\n","    image = tf.cast(image * 255.0, tf.uint8)\n","    image = tf.squeeze(image).numpy()\n","    pil_image = Image.fromarray(image)\n","    pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]].lower(), index))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uM35O-uv0iWS"},"source":["!ls test_images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aR20r4qW0jVm"},"source":["!zip -qq fmnist_test_images.zip -r test_images/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aYYUjCV0l62X"},"source":["If you are running this notebook in a Colab, you can run the cell below to download the Zip file with the images to your local disk. \n","\n","**Note**: If the Zip file does not download when you run the cell, try running the cell a second time."]},{"cell_type":"code","metadata":{"id":"tjk4537X0kWN"},"source":["try:\n","    files.download('fmnist_test_images.zip')\n","except:\n","    pass"],"execution_count":null,"outputs":[]}]}