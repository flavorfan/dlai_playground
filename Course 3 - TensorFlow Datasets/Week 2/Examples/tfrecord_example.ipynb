{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tfrecord_example.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMaL+CIyvtARxh5MA1YoJjT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zA15SS2Cwt63","executionInfo":{"status":"ok","timestamp":1602287248463,"user_tz":-480,"elapsed":2178,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHBDulejwY3e","executionInfo":{"status":"ok","timestamp":1602287295346,"user_tz":-480,"elapsed":3382,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import sys"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJjl_GwTy-Q2","executionInfo":{"status":"ok","timestamp":1602287827523,"user_tz":-480,"elapsed":907,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"c01d9c98-8ff1-4f06-9e20-ba58685112a0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.__version__"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"61vb2Yh60rfP"},"source":["# tf1 record example"]},{"cell_type":"code","metadata":{"id":"udfbJRj5w838","executionInfo":{"status":"ok","timestamp":1602287312495,"user_tz":-480,"elapsed":1562,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F8kqhAZAyhxe"},"source":["## write tfrecord file"]},{"cell_type":"code","metadata":{"id":"JKts_hpJxBgw","executionInfo":{"status":"ok","timestamp":1602287576030,"user_tz":-480,"elapsed":867,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["## data\n","corpus = np.array([[[1,2],[0,1]],[[2,4],[5,6]],[[4,2],[0,0]]])\n","seq_len = np.array([2,2,1], dtype=np.int64)\n","\n","## write tfrecord file \n","filename = 'test2.tfrecords'  # address to save the TFRecords file\n","# tf1 的老版本问题\n","# writer = tf.python_io.TFRecordWriter(filename) # AttributeError: module 'tensorflow' has no attribute 'python_io'\n","writer = tf.compat.v1.python_io.TFRecordWriter(filename)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCo-6norxJgr","executionInfo":{"status":"ok","timestamp":1602287578704,"user_tz":-480,"elapsed":857,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["for i in range(len(corpus)):    \n","    feature = {\"corpus\" : _bytes_feature(tf.compat.as_bytes(corpus[i].tostring())),\n","               \"seq_len\" : _int64_feature(seq_len[i])}\n","    example = tf.train.Example(features=tf.train.Features(feature=feature))\n","    writer.write(example.SerializeToString())"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJoGGWpSx1vl","executionInfo":{"status":"ok","timestamp":1602287639731,"user_tz":-480,"elapsed":866,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["writer.close()\n","sys.stdout.flush()"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8RQif7AydV2"},"source":["## read tfrecord file"]},{"cell_type":"code","metadata":{"id":"atc0CjWcyRkn","executionInfo":{"status":"error","timestamp":1602288206525,"user_tz":-480,"elapsed":905,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"0c47ad7f-bf7a-4aa3-db5f-d76de161a45d","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## read tfrecord file \n","corpus_list = []\n","seq_list = []\n","\n","# with tf.Session() as sess:\n","with tf.compat.v1.Session() as sess:\n","    feature = {'corpus': tf.io.FixedLenFeature([], tf.string),  #tf.FixedLenFeature -> tf.io.FixedLenFeature\n","               'seq_len': tf.io.FixedLenFeature([], tf.int64)}\n","    # Create a list of filenames and pass it to a queue\n","    filename_queue = tf.compat.v1.train.string_input_producer(['test.tfrecords'], num_epochs=1)\n","    # Define a reader and read the next record\n","    # reader = tf.TFRecordReader()\n","    reader =  tf.compat.v1.TFRecordReader()\n","    _, serialized_example = reader.read(filename_queue)\n","    # Decode the record read by the reader\n","    features = tf.compat.v1.parse_single_example(serialized_example, features=feature)\n","    # Convert the image data from string back to the numbers\n","    corpus = tf.compat.v1.decode_raw(features['corpus'], tf.int32)   \n","    # Cast label data into int32\n","    seq_len = tf.cast(features['seq_len'], tf.int32)\n","    corpus = tf.reshape(corpus, [2,2])\n","    # Creates batches by randomly shuffling tensors\n","    corpus_, seq_len_ = tf.compat.v1.train.shuffle_batch([corpus, seq_len], batch_size=1, capacity=30, num_threads=1, min_after_dequeue=10)\n","    init = tf.group(tf.compat.v1.global_variables_initializer(), tf.compat.v1.local_variables_initializer())\n","    sess.run(init)\n","    # Create a coordinator and run all QueueRunner objects\n","    coord = tf.train.Coordinator()\n","    threads = tf.compat.v1.train.start_queue_runners(coord=coord)\n","    for i in range(2):\n","        test_corpus,test_seq_len = sess.run([corpus_, seq_len_])\n","        corpus_list.append(test_corpus)\n","        seq_list.append(test_seq_len)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, 2 root error(s) found.\n","  (0) Not found: test.tfrecords; No such file or directory\n","\t [[{{node ReaderReadV2_3}}]]\n","\t [[ParseSingleExample_2/ParseExample/ParseExampleV2/_65]]\n","  (1) Not found: test.tfrecords; No such file or directory\n","\t [[{{node ReaderReadV2_3}}]]\n","0 successful operations.\n","0 derived errors ignored.\n"],"name":"stdout"},{"output_type":"error","ename":"OutOfRangeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_32_shuffle_batch_4/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[{{node shuffle_batch_4}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-b6f43ae85547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtest_corpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mcorpus_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mseq_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_32_shuffle_batch_4/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[node shuffle_batch_4 (defined at <ipython-input-24-b6f43ae85547>:23) ]]\n\nOriginal stack trace for 'shuffle_batch_4':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-b6f43ae85547>\", line 23, in <module>\n    corpus_, seq_len_ = tf.compat.v1.train.shuffle_batch([corpus, seq_len], batch_size=1, capacity=30, num_threads=1, min_after_dequeue=10)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 1347, in shuffle_batch\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 874, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3569, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"markdown","metadata":{"id":"mGE_xraB0wKt"},"source":["# tf2 record example\n","https://www.tensorflow.org/tutorials/load_data/tfrecord"]},{"cell_type":"markdown","metadata":{"id":"UIqgtmfs1mVV"},"source":["为了高效地读取数据，比较有帮助的一种做法是对数据进行序列化并将其存储在一组可线性读取的文件（每个文件 100-200MB）中。这尤其适用于通过网络进行流式传输的数据。这种做法对缓冲任何数据预处理也十分有用。\n","\n","TFRecord 格式是一种用于存储二进制记录序列的简单格式。\n","\n","协议缓冲区是一个跨平台、跨语言的库，用于高效地序列化结构化数据。\n","\n","协议消息由 .proto 文件定义，这通常是了解消息类型最简单的方法。\n","\n","tf.Example 消息（或 protobuf）是一种灵活的消息类型，表示 {\"string\": value} 映射。它专为 TensorFlow 而设计，并被用于 TFX 等高级 API。\n","\n","本笔记本将演示如何创建、解析和使用 tf.Example 消息，以及如何在 .tfrecord 文件之间对 tf.Example 消息进行序列化、写入和读取。\n","\n","注：这些结构虽然有用，但并不是强制的。您无需转换现有代码即可使用 TFRecord，除非您正在使用 tf.data 且读取数据仍是训练的瓶颈。有关数据集性能的提示，请参阅数据输入流水线性能。"]},{"cell_type":"markdown","metadata":{"id":"89ZXG6V61uid"},"source":["## 设置"]},{"cell_type":"code","metadata":{"id":"h592J3PQyqNv","executionInfo":{"status":"ok","timestamp":1602288559840,"user_tz":-480,"elapsed":839,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["import tensorflow as tf\n","\n","import numpy as np\n","import IPython.display as display"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgDq_XEF1yNw","executionInfo":{"status":"ok","timestamp":1602288571759,"user_tz":-480,"elapsed":864,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"9190a878-a4f0-4899-ba61-a1fba84e295b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.__version__"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"V3rS1Z1514Dd"},"source":["## tf.Example\n","### tf.Example 的数据类型\n","从根本上讲，tf.Example 是 {\"string\": tf.train.Feature} 映射。\n","\n","tf.train.Feature 消息类型可以接受以下三种类型（请参阅 .proto 文件）。大多数其他通用类型也可以强制转换成下面的其中一种：\n","\n","* tf.train.BytesList（可强制转换自以下类型）\n"," * string\n"," * byte\n","* tf.train.FloatList（可强制转换自以下类型）\n"," * float (float32)\n"," * double (float64)\n","* tf.train.Int64List（可强制转换自以下类型）\n"," * bool\n"," * enum\n"," * int32\n"," * uint32\n"," * int64\n"," * uint64"]},{"cell_type":"markdown","metadata":{"id":"cQaC7EPe2gVn"},"source":["为了将标准 TensorFlow 类型转换为兼容 tf.Example 的 tf.train.Feature，可以使用下面的快捷函数。请注意，每个函数会接受标量输入值并返回包含上述三种 list 类型之一的 tf.train.Feature："]},{"cell_type":"code","metadata":{"id":"DHRFLx3N11Hr","executionInfo":{"status":"ok","timestamp":1602288821310,"user_tz":-480,"elapsed":857,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# The following functions can be used to convert a value to a type compatible\n","# with tf.Example.\n","\n","def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJ5iwrvb3Hk1"},"source":["注：为了简单起见，本示例仅使用标量输入。要处理非标量特征，最简单的方法是使用 tf.io.serialize_tensor 将张量转换为二进制字符串。在 TensorFlow 中，字符串是标量。使用 tf.io.parse_tensor 可将二进制字符串转换回张量。\n","\n","下面是有关这些函数如何工作的一些示例。请注意不同的输入类型和标准化的输出类型。如果函数的输入类型与上述可强制转换的类型均不匹配，则该函数将引发异常（例如，_int64_feature(1.0) 将出错，因为 1.0 是浮点数，应该用于 _float_feature 函数）："]},{"cell_type":"code","metadata":{"id":"i81RYNvd2yC-","executionInfo":{"status":"ok","timestamp":1602288924653,"user_tz":-480,"elapsed":888,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"c654d9c8-60ae-4a6f-b3c8-4938455a368d","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["print(_bytes_feature(b'test_string'))\n","print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n","\n","print(_float_feature(np.exp(1)))\n","\n","print(_int64_feature(True))\n","print(_int64_feature(1))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["bytes_list {\n","  value: \"test_string\"\n","}\n","\n","bytes_list {\n","  value: \"test_bytes\"\n","}\n","\n","float_list {\n","  value: 2.7182817459106445\n","}\n","\n","int64_list {\n","  value: 1\n","}\n","\n","int64_list {\n","  value: 1\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JLiHKCr63LRS","executionInfo":{"status":"ok","timestamp":1602288993717,"user_tz":-480,"elapsed":901,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"1b708710-f220-47bd-93df-e8f92f1caa83","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# 可以使用 .SerializeToString 方法将所有协议消息序列化为二进制字符串：\n","feature = _float_feature(np.exp(1))\n","feature.SerializeToString()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'\\x12\\x06\\n\\x04T\\xf8-@'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"YJLOntcl3hX0"},"source":["## 创建 tf.Example 消息"]},{"cell_type":"markdown","metadata":{"id":"-OOVQfG43m8E"},"source":["假设您要根据现有数据创建 tf.Example 消息。在实践中，数据集可能来自任何地方，但是从单个观测值创建 tf.Example 消息的过程相同：   \n","\n","*  在每个观测结果中，需要使用上述其中一种函数，将每个值转换为包含三种兼容类型之一的 tf.train.Feature。\n","\n","* 创建一个从特征名称字符串到第 1 步中生成的编码特征值的映射（字典）。\n","\n","* 将第 2 步中生成的映射转换为 Features 消息。    \n","\n","在此笔记本中，您将使用 NumPy 创建一个数据集。\n","\n","此数据集将具有 4 个特征：   \n","\n","* 具有相等 False 或 True 概率的布尔特征\n","* 从 [0, 5] 均匀随机选择的整数特征\n","* 通过将整数特征作为索引从字符串表生成的字符串特征\n","* 来自标准正态分布的浮点特征      \n","请思考一个样本，其中包含来自上述每个分布的 10,000 个独立且分布相同的观测值："]},{"cell_type":"code","metadata":{"id":"rH9TS6vC3cIJ","executionInfo":{"status":"ok","timestamp":1602289198528,"user_tz":-480,"elapsed":835,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# The number of observations in the dataset.\n","n_observations = int(1e4)\n","\n","# Boolean feature, encoded as False or True.\n","feature0 = np.random.choice([False, True], n_observations)\n","\n","# Integer feature, random from 0 to 4.\n","feature1 = np.random.randint(0, 5, n_observations)\n","\n","# String feature\n","strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n","feature2 = strings[feature1]\n","\n","# Float feature, from a standard normal distribution\n","feature3 = np.random.randn(n_observations)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-xyFE5N4OJE","executionInfo":{"status":"ok","timestamp":1602289247048,"user_tz":-480,"elapsed":875,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"2df7792a-b0e5-4861-e99e-5e9f87942ad4","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["feature0"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False,  True,  True, ..., False,  True, False])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"gO2ZdPfh4Z-g","executionInfo":{"status":"ok","timestamp":1602289254670,"user_tz":-480,"elapsed":885,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"0f036db6-b463-4442-a9b8-fae5b594fd63","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["feature1"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 4, 3, ..., 0, 4, 0])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"NT7IBgGc4b1z","executionInfo":{"status":"ok","timestamp":1602289305734,"user_tz":-480,"elapsed":864,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}}},"source":["# 您可以使用 _bytes_feature、_float_feature 或 _int64_feature 将下面的每个特征强制转换为兼容 tf.Example 的类型。然后，可以通过下面的已编码特征创建 tf.Example 消息：\n","def serialize_example(feature0, feature1, feature2, feature3):\n","  \"\"\"\n","  Creates a tf.Example message ready to be written to a file.\n","  \"\"\"\n","  # Create a dictionary mapping the feature name to the tf.Example-compatible\n","  # data type.\n","  feature = {\n","      'feature0': _int64_feature(feature0),\n","      'feature1': _int64_feature(feature1),\n","      'feature2': _bytes_feature(feature2),\n","      'feature3': _float_feature(feature3),\n","  }\n","\n","  # Create a Features message using tf.train.Example.\n","\n","  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n","  return example_proto.SerializeToString()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCbUTUNn40BG"},"source":["例如，假设您从数据集中获得了一个观测值 [False, 4, bytes('goat'), 0.9876]。您可以使用 create_message() 创建和打印此观测值的 tf.Example 消息。如上所述，每个观测值将被写为一条 Features 消息。请注意，tf.Example 消息只是 Features 消息外围的包装器："]},{"cell_type":"code","metadata":{"id":"5vr13y6F4oT1","executionInfo":{"status":"ok","timestamp":1602289434942,"user_tz":-480,"elapsed":876,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"7597c185-4672-459c-cd8f-699aa4f3dca1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["example_observation = []\n","\n","serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n","serialized_example"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04[\\xd3|?'"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"luqZ0_cf425N","executionInfo":{"status":"ok","timestamp":1602289479783,"user_tz":-480,"elapsed":879,"user":{"displayName":"fan chuankang","photoUrl":"","userId":"08203141907222754677"}},"outputId":"5e489937-4a43-4a1b-eacc-b4db945c6a67","colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["# 要解码消息，请使用 tf.train.Example.FromString 方法。\n","example_proto = tf.train.Example.FromString(serialized_example)\n","example_proto"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["features {\n","  feature {\n","    key: \"feature0\"\n","    value {\n","      int64_list {\n","        value: 0\n","      }\n","    }\n","  }\n","  feature {\n","    key: \"feature1\"\n","    value {\n","      int64_list {\n","        value: 4\n","      }\n","    }\n","  }\n","  feature {\n","    key: \"feature2\"\n","    value {\n","      bytes_list {\n","        value: \"goat\"\n","      }\n","    }\n","  }\n","  feature {\n","    key: \"feature3\"\n","    value {\n","      float_list {\n","        value: 0.9876000285148621\n","      }\n","    }\n","  }\n","}"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"JRkho3I65SzP"},"source":[""],"execution_count":null,"outputs":[]}]}