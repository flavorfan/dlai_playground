{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Model subclassing](#coding_tutorial_1)\n",
    " #### [2. Custom layers](#coding_tutorial_2)\n",
    " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
    " #### [4. Custom training loops](#coding_tutorial_4)\n",
    " #### [5. tf.function decorator](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  650       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,354\n",
      "Trainable params: 1,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dropout = Dropout(0.4)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        if training:\n",
    "            x= self.dropout(x)\n",
    "        return self.dense_2(x)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1,10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  110       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  55        \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dense_3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        y1 = self.dense_2(inputs)\n",
    "        y2 = self.dense_3(y1)\n",
    "        concat = concatenate([x,y2])\n",
    "\n",
    "        return self.softmax(concat)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1,10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00662803  0.1393349  -0.0616972 ]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[-0.05792831, -0.00659737,  0.00340027],\n",
      "       [ 0.00297223,  0.03723693, -0.06611877],\n",
      "       [ 0.00816306,  0.11168672,  0.08090278],\n",
      "       [ 0.03244108, -0.04128948, -0.03365133],\n",
      "       [ 0.00772392,  0.03829811, -0.04623014]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                                initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)\n",
    "x = tf.ones((1,5))\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                                initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 2\n",
      "non-trainable weights: 0\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "non-trainable weights: 2\n"
     ]
    }
   ],
   "source": [
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=False)\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                                initializer='zeros',\n",
    "                                trainable=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)\n",
    "\n",
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "\n",
    "class MyLayerMean(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=False)\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                                initializer='zeros',\n",
    "                                trainable=False)\n",
    "        self.sum_activation = tf.Variable(initial_value=tf.zeros(units,),\n",
    "                                          trainable=False)\n",
    "        self.number_call = tf.Variable(initial_value=0,\n",
    "                                          trainable=False)                                        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        activation = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activation, axis=0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        return activation, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
    "    \n",
    "dense_layer = MyLayerMean(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04806883 -0.11332695  0.06948311]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04806883 -0.11332695  0.06948311]\n",
      "[-0.04806883 -0.11332694  0.06948311]\n"
     ]
    }
   ],
   "source": [
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1,input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "       \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.0263431  0.0352119  0.00513397 0.02417184 0.00865081 0.01223623\n",
      "  0.00692553 0.03721796 0.02306741 0.03509816 0.0060439  0.00378675\n",
      "  0.00991961 0.01528729 0.04506342 0.04279222 0.03180121 0.02186221\n",
      "  0.03147702 0.04644821 0.01308032 0.00461488 0.04086284 0.01392856\n",
      "  0.00572783 0.02023133 0.02241323 0.00414816 0.01897752 0.02909077\n",
      "  0.00522512 0.00563803 0.0177757  0.02871858 0.01446113 0.02799904\n",
      "  0.02557427 0.10738505 0.00415597 0.02368184 0.00344863 0.02835364\n",
      "  0.03041608 0.02173829 0.00479268 0.0090218 ]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_6 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout (MyDropout)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_7 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_1 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_8 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 0\n",
      "Non-trainable params: 647,214\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7facad1d8c50>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01924491 -0.02577135 -0.0165467  -0.01237216 -0.03483704 -0.0197825\n",
      " -0.01159821 -0.03234272 -0.00991911 -0.02172866 -0.02078312 -0.01833788\n",
      " -0.02507612 -0.03452985 -0.01935928 -0.00480345 -0.035322   -0.01695176\n",
      " -0.02738831 -0.03399113], shape=(20,), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.03560939], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape=(1,),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(1,),\n",
    "                                initializer='zeros')\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        return self.m * inputs + self.b\n",
    "    \n",
    "linear_regression = LinearLayer()\n",
    "\n",
    "print(linear_regression(x_train))\n",
    "print(linear_regression.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.883148\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, loss 6.883148\n",
      "Step 1, loss 5.095825\n",
      "Step 2, loss 3.773957\n",
      "Step 3, loss 2.796324\n",
      "Step 4, loss 2.073278\n",
      "Step 5, loss 1.538515\n",
      "Step 6, loss 1.143002\n",
      "Step 7, loss 0.850472\n",
      "Step 8, loss 0.634107\n",
      "Step 9, loss 0.474070\n",
      "Step 10, loss 0.355692\n",
      "Step 11, loss 0.268124\n",
      "Step 12, loss 0.203342\n",
      "Step 13, loss 0.155413\n",
      "Step 14, loss 0.119947\n",
      "Step 15, loss 0.093698\n",
      "Step 16, loss 0.074267\n",
      "Step 17, loss 0.059878\n",
      "Step 18, loss 0.049218\n",
      "Step 19, loss 0.041316\n",
      "Step 20, loss 0.035454\n",
      "Step 21, loss 0.031101\n",
      "Step 22, loss 0.027864\n",
      "Step 23, loss 0.025452\n",
      "Step 24, loss 0.023651\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "\n",
    "learning_rate = 0.05\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "    \n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "    \n",
    "    linear_regression.m.assign_sub(learning_rate *( gradients[0]))\n",
    "    linear_regression.b.assign_sub(learning_rate *( gradients[1]))\n",
    "    \n",
    "    print('Step %d, loss %f' %(i, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[1.0981834]\n",
      "b:2,  trained b:[1.8425431]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fad47ecb438>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=False)\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                                initializer='zeros',\n",
    "                                trainable=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "    \n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1,input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "       \n",
    "        return self.softmax(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01079295 0.01748509 0.01901072 0.01840391 0.00748153 0.02712965\n",
      "  0.00476022 0.06174102 0.01018737 0.0323351  0.1045867  0.02060024\n",
      "  0.01330378 0.01649857 0.04614588 0.05172708 0.00636752 0.07786792\n",
      "  0.00195756 0.00898558 0.03040092 0.02127773 0.01919735 0.00381022\n",
      "  0.00462753 0.02029436 0.01315449 0.01452187 0.03193919 0.00757006\n",
      "  0.00363247 0.01579413 0.00578874 0.00639277 0.0143002  0.03709292\n",
      "  0.00405917 0.00989403 0.0084163  0.02026028 0.00706009 0.02469634\n",
      "  0.0130174  0.04805839 0.04135852 0.01601618]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_18 (MyLayer)        multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_8 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_19 (MyLayer)        multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_9 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_20 (MyLayer)        multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_6 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 0\n",
      "Non-trainable params: 647,214\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model object\n",
    "model = MyModel(64, 10000, 64, 46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape = (input_shape[-1], self.units),\n",
    "                                initializer='random_normal',\n",
    "                                name='kernel')\n",
    "        self.b = self.add_weight(shape = (self.units,),\n",
    "                                initializer='zeros',\n",
    "                                name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "    \n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "       \n",
    "        return self.softmax(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02751595 0.00953357 0.0516496  0.00563451 0.01184839 0.01141948\n",
      "  0.00355994 0.00276473 0.0159631  0.00293087 0.09744171 0.00247092\n",
      "  0.00373612 0.00021393 0.00065385 0.05544249 0.09118371 0.00062899\n",
      "  0.00535022 0.02970869 0.10726294 0.0535985  0.00995428 0.012656\n",
      "  0.00248582 0.0109182  0.01271223 0.00127704 0.00470767 0.00362227\n",
      "  0.03498146 0.00677565 0.0105964  0.10570777 0.00671111 0.04157333\n",
      "  0.012039   0.00750054 0.01431045 0.01476845 0.00626841 0.01102041\n",
      "  0.0005704  0.00085273 0.00690607 0.07057214]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_21 (MyLayer)        multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_10 (MyDropout)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_22 (MyLayer)        multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_11 (MyDropout)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_23 (MyLayer)        multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(64,  64, 46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 000: Loss: 3.308, Accuracy: 0.494\n",
      "Epoch 001: Loss: 1.898, Accuracy: 0.616\n",
      "Epoch 002: Loss: 1.819, Accuracy: 0.665\n",
      "Epoch 003: Loss: 1.784, Accuracy: 0.684\n",
      "Epoch 004: Loss: 1.738, Accuracy: 0.691\n",
      "Epoch 005: Loss: 1.730, Accuracy: 0.695\n",
      "Epoch 006: Loss: 1.716, Accuracy: 0.698\n",
      "Epoch 007: Loss: 1.715, Accuracy: 0.705\n",
      "Epoch 008: Loss: 1.703, Accuracy: 0.706\n",
      "Epoch 009: Loss: 1.691, Accuracy: 0.702\n",
      "Duration :297.097\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # training loop\n",
    "    for x, y in train_dataset:\n",
    "        #optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        \n",
    "        #compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "    \n",
    "    # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3}\".format(epoch,\n",
    "                                                              epoch_loss_avg.result(),\n",
    "                                                              epoch_accuracy.result()))\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.813\n",
      "Test accuracy: 66.652%\n"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: earn\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "model = MyModel(64, 64, 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 000: Loss: 2.424, Accuracy: 0.556\n",
      "Epoch 001: Loss: 1.916, Accuracy: 0.654\n",
      "Epoch 002: Loss: 1.836, Accuracy: 0.675\n",
      "Epoch 003: Loss: 1.775, Accuracy: 0.685\n",
      "Epoch 004: Loss: 1.748, Accuracy: 0.691\n",
      "Epoch 005: Loss: 1.732, Accuracy: 0.693\n",
      "Epoch 006: Loss: 1.723, Accuracy: 0.696\n",
      "Epoch 007: Loss: 1.704, Accuracy: 0.702\n",
      "Epoch 008: Loss: 1.694, Accuracy: 0.704\n",
      "Epoch 009: Loss: 1.703, Accuracy: 0.704\n",
      "Duration :320.265\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # training loop\n",
    "    for x, y in train_dataset:\n",
    "        #optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        \n",
    "        #compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "    \n",
    "    # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3}\".format(epoch,\n",
    "                                                              epoch_loss_avg.result(),\n",
    "                                                              epoch_accuracy.result()))\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('grad', 'grad_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as grad_scope:\n",
      "    with tf.GradientTape() as tape:\n",
      "      loss_value = ag__.converted_call(loss, grad_scope.callopts, (model, inputs, targets, wd), None, grad_scope)\n",
      "    do_return = True\n",
      "    retval_ = grad_scope.mark_return_value((loss_value, ag__.converted_call(tape.gradient, grad_scope.callopts, (loss_value, model.trainable_variables), None, grad_scope)))\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
